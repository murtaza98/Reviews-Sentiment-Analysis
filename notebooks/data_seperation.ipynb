{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_seperation.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9fB1rFi4NbGV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The total number of reviews in dataset is 36M. Instead of training the model on the whole dataset, I have divided the dataset into small chunks and trained the model on these small chunks.\n",
        "\n",
        "This notebook will contain the code to divide the whole 36M reviews to a 8 small chunks out of which 7 will contain 5M reviews and 1 chunk will contain 1M reviews."
      ]
    },
    {
      "metadata": {
        "id": "W_EbnXtTCPGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w1CjRYYTxxpR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2mgGoc4xxlL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp /content/data_* \"/content/drive/My Drive/Machine Learning Projects/Amazon Sentiment Analysis/data/seperated_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PVO1N5l5w4lP",
        "colab_type": "code",
        "outputId": "c7d39416-edf4-43ba-87b9-24a74ed8ab33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# make directory to store data\n",
        "!mkdir data\n",
        "# get the data\n",
        "!cp '/content/drive/My Drive/Machine Learning Projects/Amazon Sentiment Analysis/data/train.ft.txt.bz2.zip' /content/data\n",
        "# extract data\n",
        "!unzip /content/data/train.ft.txt.bz2.zip\n",
        "# move extracted file\n",
        "!mv /content/train.ft.txt.bz2 /content/data/train.ft.txt.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data/train.ft.txt.bz2.zip\n",
            "  inflating: train.ft.txt.bz2        \n",
            "Archive:  /content/data/test.ft.txt.bz2.zip\n",
            "  inflating: test.ft.txt.bz2         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yNkkCYdTw4gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_file = bz2.BZ2File('/content/data/train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('/content/data/test.ft.txt.bz2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6FHvnijow4dj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_lines = train_file.readlines()\n",
        "test_lines = test_file.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPn35K2mw4ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_index = 0\n",
        "for i in range(0, len(train_lines), 500000):\n",
        "  with open('data_'+str(file_index), 'w+') as f:\n",
        "    for item in train_lines[i:i+500000]:\n",
        "      f.write(\"%s\\n\" % item.decode('utf-8'))\n",
        "    f.close()\n",
        "    file_index += 1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUahHgdTNJt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ck6vSJnJMGrb",
        "colab_type": "code",
        "outputId": "ce3a73ad-e3d5-491c-cd23-69cf528720ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1563276\n",
            "drwxr-xr-x 2 root root      4096 Jan 28 15:55 data\n",
            "-rw-r--r-- 1 root root 225769197 Jan 28 16:30 data_0\n",
            "-rw-r--r-- 1 root root 224167274 Jan 28 16:30 data_1\n",
            "-rw-r--r-- 1 root root 223818571 Jan 28 16:30 data_2\n",
            "-rw-r--r-- 1 root root 221904639 Jan 28 16:30 data_3\n",
            "-rw-r--r-- 1 root root 221089083 Jan 28 16:30 data_4\n",
            "-rw-r--r-- 1 root root 219948203 Jan 28 16:31 data_5\n",
            "-rw-r--r-- 1 root root 220033517 Jan 28 16:31 data_6\n",
            "-rw-r--r-- 1 root root  44033948 Jan 28 16:31 data_7\n",
            "drwx------ 3 root root      4096 Jan 28 15:54 drive\n",
            "drwxr-xr-x 1 root root      4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Idmtw9cgMy4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}